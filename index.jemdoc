# jemdoc: menu{MENU}{index.html}
= Di Hu

~~~
{}{img_left}{ims/self_5.png}{alt text}{}{280px}{}
Di Hu  胡 迪\n
Assistant Professor (tenure-track) \n 
[http://ai.ruc.edu.cn/ Gaoling School of Artificial Intelligence], [https://www.ruc.edu.cn/ Renmin University of China] \n
Contact: dihu\[at\]ruc.edu.cn, [https://github.com/DTaoo Github], [https://www.zhihu.com/column/c_1280978171983507456 Zhihu], [papers/DTao_Resume.pdf Resume]
~~~

== Short Bio 
I'm tenure-track faculty at [http://ai.ruc.edu.cn/ Gaoling School of Artificial Intelligence], [https://www.ruc.edu.cn/ Renmin University of China]. Before that, I was previously a research scientist at [http://research.baidu.com/ Baidu Research]. I obtained the PhD degree from [http://en.nwpu.edu.cn Northwestern Polytechnical University] in 2019, supervised by [https://scholar.google.com.hk/citations?user=ahUibskAAAAJ&hl=zh-CN Xuelong Li], [https://scholar.google.com.hk/citations?user=FRyuu2IAAAAJ&hl=zh-CN Xiaoqiang Lu], and [http://www.escience.cn/people/fpnie/index.html Feiping Nie]. What I met, told and learned in the Center for OPTical IMagery Analysis and Learning (OPTIMAL) led by Prof. [https://scholar.google.com.hk/citations?user=ahUibskAAAAJ&hl=zh-CN Xuelong Li] have undoubtedly made great impacts on me. Great Thanks!

Currently, I'm leading the [https://gewu-lab.github.io/ GeWu Lab] and exploring how to understand and interact with the world via the natural multimodal messages. I'm strongly convinced that the pervasive and free correspondence between multimodal messages can provide sufficient information for perceiving, learning and understanding environment, even the agent itself, which promisingly makes multimodal perception become one of the key to achieve machine intelligence.

*I'm always looking for self-motivated Ph.D and Master students, also including visiting students.* If you're interested, please drop me your email!


== Recent News
- \[11-10-2022\] Two papers accepted by WACV 2022! Congrats to Xinchi, DongZhan!
- \[25-08-2022\] We wrote an article about recent advances in audio-visual learning, Please check [https://gewu-lab.github.io/audio-visual-learning/ here]!  
- \[24-08-2022\] Dr. Di Hu gave a talk @Valse 2022 in Tian Jin. Please find slides [materials/VALSE-2022-DiHu.pdf here]!
- \[12-07-2022\] Dr. Di Hu was invited as the Senior PC Member in AAAI 2023.
- \[11-07-2022\] Dr. Di Hu will chair the "Audiovisual Enhancement" session in ICME 2022.
- \[11-03-2022\] One paper accepted by TMM. Congrats to all the co-authors!
- \[02-03-2022\] Two papers accepted by CVPR 2022, both are *ORAL* presentation! Congrats to Guangyao, Xiaokang, Yake and Andong!
- \[23-12-2021\] Dr. Di Hu was selected for the Young Elite Scientists Sponsorship Program by CAST!
- \[10-12-2021\] One paper accepted by TPAMI, Congrats to Yake and other co-authors!
- \[01-12-2021\] Two papers accepted by AAAI 2022, Congrats to all the authors!
- \[28-10-2021\] Dr. Di Hu won the 2021 Outstanding Doctoral Dissertation Award of SHAANXI Province!
- \[03-08-2021\] Predicting sound by clicking on Google Earth! One collaborative work with TUM, DLR and MIT. Here are the [https://arxiv.org/abs/2108.00688 paper] and [https://www.youtube.com/watch?v=gD_fNJPBWhs demo]!
- \[20-06-2021\] All the slides and videos have been released for [https://audio-visual-scene-understanding.github.io/ the CVPR2021 Tutorial on Audio-visual Scene Understanding]!
- \[23-04-2021\] One paper accepted by KAIS. Congrats to all the authors!
- \[01-03-2021\] Two papers accepted by CVPR 2021, with one Oral paper!
- \[01-02-2021\] Will co-organize the CVPR2021 Tutorial on Audio-visual Scene Understanding!
- \[09-01-2021\] Co-organized the WACV2021 Tutorial on Audio-visual Scene Understanding and gave two talks. Please find more [https://echo0409.github.io/Audio-Visual-Scene-Understanding/ here]!
- \[02-12-2020\] One paper accepted by AAAI 2021! Congrats to my friend, [https://redwang.github.io/ Dong]! Code will be released soon!
- \[25-11-2020\] Dr. Di Hu gave a talk @ [http://valser.org/article-391-1.html VALSE Webinar]. Please find slides [https://zenodo.org/record/4289865/files/%E5%90%AC%E5%A3%B0%E8%AF%86%E7%89%A9%E4%B8%8E%E8%BE%A8%E7%89%A9%E7%9F%A5%E5%A3%B0.pptx?download=1 here]!
- \[25-09-2020\] One paper accepted by NeurIPS 2020! Code has been released [https://github.com/DTaoo/Discriminative-Sounding-Objects-Localization here]!
- \[14-09-2020\] Dr. Di Hu won the 2020 [https://en.caai.cn/ CAAI] Outstanding Doctoral Dissertation Award!
- \[01-07-2020\] Two papers accepted by ECCV 2020!
- \[25-05-2020\] Four papers accepted by CVPR Workshop 2020!
- \[26-08-2019\] Dr. Di Hu won the 2019 ACM Xi'an Doctoral Dissertation Award!

== Research Interests 
- Multimodal Machine Learning
- Machine Multimodal Perception

== Course 
- Artificial Intelligence and Python Programming (Undergraduate, Spring, 2021 and 2022)
- Pattern Recognition and Computer Vision (Graduate, Spring, 2021 and 2022)


== Services and Experiences
- Senior PC Member and Session Chair: AAAI 2023, ICME 2022
- PC Member: ICML 2021-2022, NeurIPS 2020-2021, CVPR 2018 2020-2022, ICCV 2019-2021, ECCV 2020, AAAI 2018 2020-2022, ACCV 2018 2020, WACV 2021
- Co-organizer: ICDM 2019 Tutorial on [https://baiduautodl.com/ Automated Deep Learning: Theory, Algorithms, Platforms, and Applications]
- Co-organizer: WACV2021 Tutorial on [https://echo0409.github.io/Audio-Visual-Scene-Understanding/ Audio-visual Scene Understanding]
- Co-organizer: CVPR2021 Tutorial on [https://audio-visual-scene-understanding.github.io/ Audio-visual Scene Understanding]
- CVPR 2019 Doctoral Consortium: Had a memorable discussion with [https://www.cs.cmu.edu/~morency/ Prof. Morency]
